{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "device = torch.device('cpu')\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "#load training data set.\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "#Load testing data set.\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of classes: \n",
      " {'T-shirt/top': 6000, 'Trouser': 6000, 'Pullover': 6000, 'Dress': 6000, 'Coat': 6000, 'Sandal': 6000, 'Shirt': 6000, 'Sneaker': 6000, 'Bag': 6000, 'Ankle boot': 6000}\n"
     ]
    }
   ],
   "source": [
    "'''Checking the data set classes and amount of data in each class.'''\n",
    "idx2class = {v: k for k, v in train_dataset.class_to_idx.items()}\n",
    "def get_class_distribution(dataset_obj):\n",
    "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
    "    \n",
    "    for element in dataset_obj:\n",
    "        y_lbl = element[1]\n",
    "        y_lbl = idx2class[y_lbl]\n",
    "        count_dict[y_lbl] += 1\n",
    "            \n",
    "    return count_dict\n",
    "print(\"Distribution of classes: \\n\", get_class_distribution(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "total_classes = 10\n",
    "epochs_count = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This method returns the subset of give dataset; all the classes will have same no of samples given as count.'''\n",
    "def get_subset(dataset, count):\n",
    "    targets = np.array(dataset.targets)\n",
    "    classes, class_counts = np.unique(targets, return_counts=True)\n",
    "    nb_classes = len(classes)\n",
    "    # Get class indices\n",
    "    class_indices = [np.where(targets == i)[0] for i in range(nb_classes)]\n",
    "    fullindices = []\n",
    "    for labels in class_indices:\n",
    "        fullindices.extend(random.sample(list(labels), count))\n",
    "    sub_dataset = torch.utils.data.Subset(dataset, fullindices)\n",
    "    return sub_dataset\n",
    "\n",
    "#print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For different configuration just uncomment below line and execute all cells.'''\n",
    "#train_dataset_subset = get_subset(train_dataset, 100)\n",
    "train_dataset_subset = get_subset(train_dataset, 500)\n",
    "#train_dataset_subset = get_subset(train_dataset, 1000)\n",
    "#train_dataset_subset = get_subset(train_dataset, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 500,\n",
       "         1: 500,\n",
       "         2: 500,\n",
       "         3: 500,\n",
       "         4: 500,\n",
       "         5: 500,\n",
       "         6: 500,\n",
       "         7: 500,\n",
       "         8: 500,\n",
       "         9: 500})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Check the subset class distribution'''\n",
    "train_classes = [label for _, label in train_dataset_subset]\n",
    "Counter(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset_subset, batch_size=batch_size)\n",
    "\n",
    "'''For running on the full dataset, uncomment this line and comment above line.'''\n",
    "#train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP with 2 layers\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, total_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.n_images_per_class = 1000\n",
    "        self.n_classes = 10\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.l2 = torch.nn.Linear(hidden_size, total_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel = NeuralNet(input_size, hidden_size, total_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Cross Entropy Loss.\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "#Using Adam optimizer\n",
    "optimizer = torch.optim.Adam(nnmodel.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the NN\n",
    "steps = len(train_loader)\n",
    "for epoch in range(epochs_count):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = nnmodel(images)\n",
    "        loss = cross_entropy_loss(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{epochs_count}], Step [{i+1}/{steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test images: 24.78 %\n"
     ]
    }
   ],
   "source": [
    "# Test the NN\n",
    "with torch.no_grad():\n",
    "    nn_correct = 0\n",
    "    nn_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = nnmodel(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        nn_samples += labels.size(0)\n",
    "        nn_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * nn_correct / nn_samples\n",
    "    print(f'Accuracy of the network on test images: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        11\n",
      "           1       1.00      0.00      0.00        12\n",
      "           2       1.00      0.00      0.00         6\n",
      "           3       0.20      0.29      0.24         7\n",
      "           4       0.11      0.25      0.15         8\n",
      "           5       0.33      0.55      0.41        11\n",
      "           6       0.20      0.67      0.30        12\n",
      "           7       0.46      0.86      0.60         7\n",
      "           8       1.00      0.00      0.00        14\n",
      "           9       1.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.24       100\n",
      "   macro avg       0.63      0.26      0.17       100\n",
      "weighted avg       0.67      0.24      0.15       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(labels, predicted, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 2 0 9 0 0 0]\n",
      " [0 0 0 8 3 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 5 0 0 0]\n",
      " [0 0 0 2 5 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 6 0 0 0]\n",
      " [0 0 0 0 0 6 1 4 0 0]\n",
      " [0 0 0 0 4 0 8 0 0 0]\n",
      " [0 0 0 0 0 1 0 6 0 0]\n",
      " [0 0 0 0 1 4 9 0 0 0]\n",
      " [0 0 0 0 0 7 2 3 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(labels,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
